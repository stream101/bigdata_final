{
 "metadata": {
  "name": "",
  "signature": "sha256:426afe70bae657faf43e90cf7e181a47f776210bfcd3af2adccc625a369f62e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<p>In this notebook, I will do the following things: </p>\n",
      "<p>(1) Global trend analysis </p> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "import sys,os\n",
      "\n",
      "cwd=os.getcwd()\n",
      "path=cwd.split('/')\n",
      "home_dir='/'.join(path[:-2])\n",
      "print home_dir\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "\n",
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData\n",
        "['launcher', 'mrjob']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "x7jin\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile calc_global.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurement for each year\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import re,pickle,base64,zlib\n",
      "import csv\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        super(MRWeather, self).__init__(*args, **kwargs)\n",
      "        self.valid_stations = {}\n",
      "    \n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stationyear')\n",
      "    \n",
      "    def mapper_init(self):\n",
      "        f= open(self.options.stationyear,'rb')\n",
      "        reader = csv.reader(f)\n",
      "        for line in reader:\n",
      "            try:\n",
      "                st = line[0]\n",
      "                year = int(line[1])\n",
      "                if st in self.valid_stations:\n",
      "                    self.valid_stations[st].append(year)\n",
      "                else:\n",
      "                    self.valid_stations[st] = [year]\n",
      "            except Exception as e: \n",
      "                pass\n",
      "        f.close()\n",
      "    \n",
      "    \n",
      "    def mapper(self, _, line):\n",
      "        \n",
      "        self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "        elements=line.split(',')\n",
      "        # 0: station 2: date 3: mean temp 11: visibility 17: max 18: min\n",
      "        #out = (elements[0], (elements[3], elements[11], elements[17], elements[18]))\n",
      "        year = int(elements[2])/10000\n",
      "        mean_temp = float(elements[3])\n",
      "        max_temp = float(elements[17].replace('*', ''))\n",
      "        min_temp = float(elements[18].replace('*', ''))\n",
      "        visible = float(elements[11])\n",
      "        out = (year, (mean_temp, max_temp, min_temp, visible))\n",
      "        #out = (year, min_temp)\n",
      "        #if mean_temp != 9999.9 and max_temp != 9999.9 and min_temp != 9999.9 and visible != 999.9:\n",
      "        yield out\n",
      "\n",
      "        \n",
      "    def reducer(self, station, info):\n",
      "        \n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        info_list = list(info)\n",
      "        max_sum = 0.0\n",
      "        min_sum = 0.0\n",
      "        mean_sum = 0.0\n",
      "        visible_sum = 0.0\n",
      "        num = len(info_list)\n",
      "        for i in range(0, num):\n",
      "            mean_sum = mean_sum + info_list[i][0]\n",
      "            max_sum = max_sum + info_list[i][1]\n",
      "            min_sum = min_sum + info_list[i][2]\n",
      "            visible_sum = visible_sum + info_list[i][3]\n",
      "        yield(station, (mean_sum/num, max_sum/num, min_sum/num, visible_sum/num)     \n",
      "     \n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting calc_global.py\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python calc_global.py -r emr --emr-job-flow-id $job_flow_id s3://xinxin.bucket/data/gsod.all.tsv --stationyear ~/UCSD_BigData/data/weather/ncdc/valid_station_year.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}